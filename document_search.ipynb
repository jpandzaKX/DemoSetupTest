{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3280b01a-d3b7-4ef6-9494-789d15bc48ec",
   "metadata": {},
   "source": [
    "# Semantic Search on PDF Documents with KDB.AI\n",
    "\n",
    "This example demonstrates how to use KDB.AI to run semantic search on unstructured text documents. \n",
    "\n",
    "Semantic search allows users to perform searches based on the meaning or similarity of the data rather than exact matches. It works by converting the query into a vector representation and then finding similar vectors in the database. This way, even if the query and the data in the database are not identical, the system can identify and retrieve the most relevant results based on their semantic meaning.\n",
    "\n",
    "## Aim\n",
    "In this tutorial, we'll walk you through the process of performing semantic search on documents, taking PDFs as example, using KDB.AI as the vector store. We will cover the following topics:\n",
    "\n",
    "- How to create vector embeddings using Sentence Transformer\n",
    "- How to store those embeddings in KDB.AI\n",
    "- How to search with a query using KDB.AI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96697d51-a815-4ee9-acef-555afe28c2b6",
   "metadata": {},
   "source": [
    "## 1. Load and Split Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427beb75-cc0a-4a00-a64b-c7a80e197f67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%pip install PyPDF2 spacy sentence-transformers kdbai_client -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6847ec-9cef-4648-82b9-b888620f7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m spacy download en_core_web_sm -q\n",
    "!python3 -m spacy download en_core_web_sm -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2992812-4705-489d-974f-b7b44132343a",
   "metadata": {},
   "source": [
    "### Load and Split PDF into Sentences\n",
    "\n",
    "We leverage the power of PyPDF2 for PDF processing and spaCy for advanced natural language processing. The code below extracts content from each page of the PDF and processes it to identify sentences.\n",
    "\n",
    "The PDF we are using is [this research paper](https://arxiv.org/pdf/2308.05801.pdf) presenting information on the formation of Interstellar Objects in the Milky Way. It is also available on our [GitHub](https://github.com/KxSystems/kdbai-notebooks/tree/main/notebooks/samples/document-search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbf9ede-6ed3-4171-bc77-2da673dcff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import spacy\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def split_pdf_into_sentences(pdf_path):\n",
    "    # Open the PDF file\n",
    "    with open(pdf_path, \"rb\") as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "        # Extract text from each page and concatenate\n",
    "        full_text = \"\"\n",
    "        for page_number in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_number]\n",
    "            full_text += page.extract_text()\n",
    "\n",
    "        # Process the text using spaCy for sentence tokenization\n",
    "        doc = nlp(full_text)\n",
    "        sentences = [sent.text for sent in doc.sents]\n",
    "\n",
    "        return sentences\n",
    "\n",
    "\n",
    "# Define PDF path\n",
    "pdf_path = \"data/research_paper.pdf\"\n",
    "\n",
    "# Split the PDF into sentences\n",
    "pdf_sentences = split_pdf_into_sentences(pdf_path)\n",
    "len(pdf_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558747e-4559-44b2-8ecb-88a583cc0ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pdf_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ea4179-8b26-4c40-89aa-ef6da11aafdf",
   "metadata": {},
   "source": [
    "## 2. Create Vector Embeddings \n",
    "\n",
    "Next, we use the Sentence Transformers library to create embeddings for our collection of sentences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae1706a-6046-4dae-9b54-a59d4805f286",
   "metadata": {},
   "source": [
    "### Selecting a Sentence Transformer Model\n",
    "\n",
    "There are 100+ of different types of Sentence Transformers models available - see [HuggingFace](https://huggingface.co/sentence-transformers) for the full list. The diversity among these primarily stems from variations in their training data. Selecting the ideal model for your needs involves matching the domain and task closely, while also considering the benefits of incorporating larger datasets to enhance scale. \n",
    "\n",
    "This tutorial will use the `all-MiniLM-L6-v2` pre-trained model. This embedding model can create sentence and document embeddings that can be used for a wide variety of tasks including semantic search which makes it a good choice for our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823cc952-139a-49be-b5eb-802554aed708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4aaf7-69c5-4c56-b058-32ced66a62ee",
   "metadata": {},
   "source": [
    "### Generate Embeddings\n",
    "\n",
    "We prepare embeddings by applying the sentence transformer model to our sentences to encode them. The we do some transformation to get this into DataFrame which is the format accepted by KDB.AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d05b99a-121c-429e-864a-ee4bc5739224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create embeddings\n",
    "embeddings_array = model.encode(np.array(pdf_sentences))\n",
    "embeddings_list = embeddings_array.tolist()\n",
    "\n",
    "print(embeddings_list)\n",
    "\n",
    "embeddings_df = pd.DataFrame({\"vectors\": embeddings_list, \"sentences\": pdf_sentences})\n",
    "#embeddings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd119e3",
   "metadata": {},
   "source": [
    "It is important to note the dimension of our embeddings is 384. This will need to match the dimensions we set in the KDB.AI index in the next step. We can easily check this using `len` to count elements in our vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70505eae-4138-4ba8-80e9-fc13c37d0b32",
   "metadata": {},
   "source": [
    "## 3. Store Embeddings in KDB.AI\n",
    "\n",
    "With the embeddings created, we need to store them in a vector database to enable efficient searching. KDB.AI is perfect for this task.\n",
    "\n",
    "### Connect to KDB.AI Session\n",
    "\n",
    "To use KDB.AI, you will need two session details - a URL endpoint and an API key. To get these you can sign up for free [here](https://trykdb.kx.com/kdbai/signup).\n",
    "\n",
    "You can connect to a KDB.AI session using `kdbai.Session`. Enter the session URL endpoint and API key details from your KDB.AI Cloud portal below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kdbai_client as kdbai\n",
    "from getpass import getpass\n",
    "\n",
    "'''\n",
    "KDBAI_ENDPOINT = input('KDB.AI endpoint: ')\n",
    "KDBAI_API_KEY = getpass('KDB.AI API key: ')\n",
    "session = kdbai.Session(api_key=KDBAI_API_KEY, endpoint=KDBAI_ENDPOINT)\n",
    "'''\n",
    "''' KDBAI Server (Local) '''\n",
    "#session = kdbai.Session(endpoint='http://kdbaiServer:8082')\n",
    "\n",
    "''' KDBAI Server (Docker) '''\n",
    "session = kdbai.Session(endpoint='http://kdbaiServer:8082')\n",
    "\n",
    "''' KDBAI cloud '''\n",
    "#session = kdbai.Session(api_key=\"73c70f55e3-zwTcApmr1LHpOkv4sXQMdjTKFl/t7lXARtfpvOtitkzIQN5/YB+sT/EAe99sjuHZ5Y/10O9gSvDTRFh1\", endpoint=\"https://cloud.kdb.ai/instance/wge9zktpsm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c6525c",
   "metadata": {},
   "source": [
    "### Define Schema\n",
    "\n",
    "The next step is to define a schema for our KDB.AI table where we will store our embeddings. Our table will have one column called `vectors`.\n",
    "\n",
    "At this point you will select the index and metric you want to use for searching.\n",
    "\n",
    "With KDB.AI we have the choice between HNSW (Hierarchical Navigable Small World) and Flat indexing methods. Generally, for semantic search of documents, the HNSW indexing method might be more suitable. Here's why:\n",
    "\n",
    "- **Search Speed and Approximation**: HNSW is designed for fast approximate nearest neighbour searches. It can efficiently handle high-dimensional data, which is common in natural language processing tasks involving text documents.\n",
    "- **Semantic Representation**: The Sentence Transformers library, used in this example, generates embeddings that capture semantic meaning. HNSW is well-suited for indexing such embeddings and performing semantic searches.\n",
    "- **Scalability**: HNSW is scalable and can handle large datasets effectively, making it suitable for applications with a vast number of documents.\n",
    "\n",
    "HNSW provides approximate search results, meaning that the nearest neighbors might not be exact matches but are close in terms of similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af604df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_schema = {\n",
    "    \"columns\": [\n",
    "        {\"name\": \"sentences\", \"pytype\": \"str\"},\n",
    "        {\n",
    "            \"name\": \"vectors\",\n",
    "            \"vectorIndex\": {\"dims\": 384, \"metric\": \"L2\", \"type\": \"hnsw\"},\n",
    "        },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518cfe1e",
   "metadata": {},
   "source": [
    "### Create and Save Table\n",
    "\n",
    "Use `create_table` to create a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d190db-7c19-418e-9140-3dff04c9d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    table = session.create_table(\"pdf\", pdf_schema)\n",
    "except:\n",
    "    table = session.table(\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466068bc",
   "metadata": {},
   "source": [
    "We can use `query` to see our table exists but is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.query()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a9d0e-80b8-4e09-9101-d22667da551f",
   "metadata": {},
   "source": [
    "### Add Embeddings to Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cc156c-8071-4784-8c3e-a049b61e8668",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.insert(embeddings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31a4ecd",
   "metadata": {},
   "source": [
    "Re-running `query` we can now see data has been added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ecb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.query()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ddb725-e0e7-4c00-a22b-3234eacf6bd1",
   "metadata": {},
   "source": [
    "## 4. Searching with a Query using KDB.AI\n",
    "\n",
    "Now that the embeddings are stored in KDB.AI, we can perform semantic search using `search`. \n",
    "\n",
    "First, we embed our search term using the Sentence Transformer model as before. Then we search our index to return the three most similar vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8666561e-e9b2-4c9f-95f4-add789be416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"number of interstellar objects in the milky way\"\n",
    "search_term_vector = model.encode(search_term)\n",
    "search_term_list = [search_term_vector.tolist()]\n",
    "\n",
    "results = table.search(search_term_list, n=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91762de7",
   "metadata": {},
   "source": [
    "The results returned from `table.search` show the closest matches along with value of nearest neighbour distances `nn_distance`. Let's print the output so we can see the full sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f5ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "results[0][\"sentences\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff8ba0",
   "metadata": {},
   "source": [
    "We can see these sentences do reference our search term 'number of interstellar objects in the milky way' in some way. Let's try another search term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f624af-a151-40e5-9a6f-9e7253f038fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"how does planet formation occur\"\n",
    "#search_term = \"who is the author\"\n",
    "search_term_vector = model.encode(search_term)\n",
    "search_term_list = [search_term_vector.tolist()]\n",
    "\n",
    "results = table.search(search_term_list, n=3)\n",
    "results[0][\"sentences\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ce337f",
   "metadata": {},
   "source": [
    "Again, we can see these sentences do reference our search term 'how does planet formation occur' in some way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab60efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.list()\n",
    "table.drop()\n",
    "session.list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
